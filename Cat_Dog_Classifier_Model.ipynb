{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPk8lWXQ0h2/urY0FUJfBcL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhayk-c/Cat-Dog-Classifier-Model/blob/main/Cat_Dog_Classifier_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Environment Setup"
      ],
      "metadata": {
        "id": "UEorxbleu0U_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "beiKhSfLOz5c"
      },
      "outputs": [],
      "source": [
        "# Environment setup\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Create our Data Set\n",
        "\n",
        "We create our data set by scraping the web for cat and dog images. We use the duckduckgo search engine because it's API is relatively easy to work with."
      ],
      "metadata": {
        "id": "VRosCoS6u-zL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's define a function that can download categories of images for us.\n",
        "# We download images using duckduckgo's image search engine.\n",
        "def download_image_categories(path: Path, categories: List[str], max_images_per_category):\n",
        "  if not path.exists():\n",
        "    path.mkdir()\n",
        "    for img_category in categories:\n",
        "      dest = (path/img_category)\n",
        "      dest.mkdir(exist_ok=True)\n",
        "      results = search_images_ddg(img_category, max_images_per_category)\n",
        "      download_images(dest, urls=results)"
      ],
      "metadata": {
        "id": "B8yYBLQeP-ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using our helper function let's download images of cats and dogs from the web\n",
        "# and save them in our file system in a training_data/ folder.\n",
        "training_data_folder = Path('training_data')\n",
        "download_image_categories(training_data_folder, ['pet cat', 'wild cat', 'pet dog', 'wild dog'], 100)\n",
        "\n",
        "# Delete any invalid image files that get downloaded.\n",
        "image_paths = get_image_files(training_data_folder)\n",
        "failed = verify_images(image_paths)\n",
        "failed.map(Path.unlink)"
      ],
      "metadata": {
        "id": "wOIQQhyMTADf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It's useful to save a backup of the downloaded data set for debugging\n",
        "# and reuse purposes so saving a backup here so it can be downloaded if needed.\n",
        "!ls\n",
        "!zip -r training_data.zip training_data/\n",
        "\n",
        "#!unzip training_data.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "UU-WxWn3NVDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Let's train our ML Model\n",
        "\n",
        "Now we train our ML Model to classify cats and dogs. We leverage the transfer learning technique to fine tune the popular resnet18 image model to specifically classify cats and dogs. We use fastAI framework and vision learner for quicker prototyping and training because it provides a lot of conveniences we can reuse."
      ],
      "metadata": {
        "id": "2XVl626JvZaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define a custom function that generates our training data's labels.\n",
        "def get_classification_label(o):\n",
        "  input_image_path = Path(o)\n",
        "  path_components = input_image_path.parts\n",
        "  parent_dir = path_components[len(path_components) - 2]\n",
        "  tokens = parent_dir.split()\n",
        "  if \"dog\" in tokens:\n",
        "    return \"dog\"\n",
        "  elif \"cat\" in tokens:\n",
        "    return \"cat\"\n",
        "\n",
        "# Define our data block that we will use to create our DataLoaders object.\n",
        "# We resize our image to 224x224, which is the size dimenstion the resnet18 image\n",
        "# model expects. Additionally we use a RandomResizedCrop transform to randomly\n",
        "# crop to different sections of the image (a common data augmentation technique) used\n",
        "# when training image models. Furthermore we will apply a standard set of data augmentation\n",
        "# transforms to the images in \"batch\" during model training leveraging the convenient FastAI\n",
        "# aug_transforms() function.\n",
        "data_block = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=get_classification_label,\n",
        "    item_tfms=[RandomResizedCrop(224, min_scale=0.5)],\n",
        "    batch_tfms=aug_transforms())\n",
        "data_loaders = data_block.dataloaders(Path('training_data'))\n",
        "data_loaders.train.show_batch(max_n=4, nrows=1)\n",
        "\n",
        "# Now we train our cat and dog image classifier model using fine tuning\n",
        "# \"transfer learning\" approach\n",
        "learn = vision_learner(data_loaders, resnet18, metrics=error_rate)\n",
        "learn.fine_tune(4)"
      ],
      "metadata": {
        "id": "H03NcFnjt-yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Clean data, export model, evaluate\n",
        "\n",
        "We now evaluate our classifier's performance and export/save it for use in applications or further ML model tuning/training."
      ],
      "metadata": {
        "id": "TfEp3ADnwKRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot the model confusion matrix and top losses to see how\n",
        "# the model is performing.\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()\n",
        "interp.plot_top_losses(5, nrows=1)"
      ],
      "metadata": {
        "id": "6vds8G27wTEg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use fastAI's data cleaner widget to see the top losses in our data set for\n",
        "# each category and clean our data set if needed.\n",
        "# This is a useful debugging/visualization but the data set was manually cleaned\n",
        "# already before hand so everything looks good.\n",
        "from fastai.vision.widgets import *\n",
        "cleaner = ImageClassifierCleaner(learn)\n",
        "cleaner"
      ],
      "metadata": {
        "id": "XLd9F-OMxOAi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model has been trained and data set looks cleaned lets export our model\n",
        "learn.export('cat_dog_classifier_model.pkl')"
      ],
      "metadata": {
        "id": "H8MugkGYyYNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now load the exported ML model and test the inferencing quality.\n",
        "# I manually created my own test set with dogs, cats, and pictures of other animals/objects.\n",
        "# Feel free to create your own test image folder and you can reuse the cell here to test\n",
        "# model quality. This cell can be removed and replaced.\n",
        "\n",
        "#!unzip test_data.zip\n",
        "\n",
        "model_inference = load_learner('cat_dog_classifier_model.pkl')\n",
        "print(model_inference.dls.vocab)\n",
        "\n",
        "# 63% accuracy\n",
        "print(model_inference.predict('test_data/dogs/Dog1.jpg'))\n",
        "print(model_inference.predict('test_data/dogs/Dog2.jpeg'))\n",
        "print(model_inference.predict('test_data/dogs/Dog3.jpeg'))\n",
        "print(model_inference.predict('test_data/dogs/Dog4.jpg'))\n",
        "print(model_inference.predict('test_data/dogs/Dog5.jpg'))\n",
        "print(model_inference.predict('test_data/dogs/Dog6.jpg'))\n",
        "print(model_inference.predict('test_data/dogs/Dog7.jpg'))\n",
        "\n",
        "# 100% accuracy\n",
        "print(model_inference.predict('test_data/cats/Cat1.jpg'))\n",
        "print(model_inference.predict('test_data/cats/Cat2.jpg'))\n",
        "print(model_inference.predict('test_data/cats/Cat3.jpeg'))\n",
        "print(model_inference.predict('test_data/cats/Cat4.jpeg'))\n",
        "print(model_inference.predict('test_data/cats/Cat5.jpg'))\n"
      ],
      "metadata": {
        "id": "iKhmcsN82KPY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Results and Conclusion"
      ],
      "metadata": {
        "id": "Yzz1_1hzPC3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "1. The model has a 75% accuracy rate on the test data.\n",
        "2. The model is better at classifying cats vs dogs (100% vs 63%)\n",
        "3. The reason for the inconsistency is in the training data. The downloaded training data set for cats represents a wider distribution of cat breeds, species, and sizes. The downloaded training data for dogs heavily skews towards certain popular domestic dog breeds, small size dogs, and puppies.\n",
        "\n",
        "**Improving Model Quality**\n",
        "- In order to improve the model quality I would introduce more distribution of dog breeds (both wild/stray and domestic) in the training set which should improve the prediction accuracy of the dog label.\n",
        "- I would also introduce real world images into both training sets (captured on iphones, shared in social media/applications). I noticed the model performed well on web images and prediction quality degraded a bit on images captured on friends iPhones.\n",
        "\n",
        "**A note on the Classifier**\n",
        "- The model will ONLY work on images of cats and dogs. If an image other than a cat or dog is provided the behavior is undefined, it will likely predict a cat or dog label with high confidence.\n",
        "- This is because this model was only trained on labeled cat and dog data, to accurately predict the inverse case (not a dog or cat), a newly labeled data set with a label of \"unknown\" that contains a wide distribution of non-cat/non-dog objects is needed. Due to time needed in creating such data set I did not introduce this into the training data but it could easily be done.\n",
        "\n"
      ],
      "metadata": {
        "id": "g7wnGBa5O8zk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RY48SN0yPxiZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}